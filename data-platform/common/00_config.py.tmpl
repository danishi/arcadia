# ==============================================================================
# ARCADIA Data Platform - Common Configuration
# Generated by ARCADIA Framework (Phase F)
#
# Usage:
#   1. Copy this file: cp 00_config.py.tmpl 00_config.py
#   2. Replace {{PLACEHOLDER}} values with your project settings
#   3. Other scripts import this module for shared configuration
# ==============================================================================

# ------------------------------------------------------------------------------
# Project Settings
# ------------------------------------------------------------------------------

# Project identifier (alphanumeric + underscore, used as catalog/database prefix)
PROJECT_SLUG = "{{PROJECT_SLUG}}"

# Target platform: databricks | snowflake | bigquery | custom
PLATFORM_TYPE = "{{PLATFORM_TYPE}}"

# ------------------------------------------------------------------------------
# Medallion Architecture - Schema / Dataset Names
# ------------------------------------------------------------------------------

SCHEMA_BRONZE = "bronze"
SCHEMA_SILVER = "silver"
SCHEMA_GOLD = "gold"

# Landing zone name (Databricks Volume / Snowflake Stage / GCS bucket prefix)
LANDING_ZONE = "raw_landing"

# ------------------------------------------------------------------------------
# Sample Data Scale
# Adjust these numbers based on demo requirements.
# Larger values produce more realistic distributions but take longer to generate.
# ------------------------------------------------------------------------------

NUM_CUSTOMERS = 200
NUM_ACCOUNTS = 500           # Typically 2-3x customers
NUM_TRANSACTIONS = 10000     # 1 year of transaction history
NUM_CAMPAIGNS = 15
NUM_CAMPAIGN_RESPONSES = 3000
NUM_WEB_EVENTS = 5000        # 90 days of web activity
RANDOM_SEED = 42             # For reproducible data generation

# ------------------------------------------------------------------------------
# Platform-Specific Settings (override per platform)
# ------------------------------------------------------------------------------

# Databricks
DATABRICKS_CATALOG_LOCATION = "{{CATALOG_LOCATION}}"  # e.g., s3://bucket/unity-catalog/...

# Snowflake (stub - for future use)
# SNOWFLAKE_WAREHOUSE = "{{SNOWFLAKE_WAREHOUSE}}"
# SNOWFLAKE_DATABASE = "{{SNOWFLAKE_DATABASE}}"
# SNOWFLAKE_ROLE = "{{SNOWFLAKE_ROLE}}"

# BigQuery (stub - for future use)
# GCP_PROJECT_ID = "{{GCP_PROJECT_ID}}"
# BQ_LOCATION = "{{BQ_LOCATION}}"  # e.g., asia-northeast1

# ------------------------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------------------------

def fqn(schema: str, table: str) -> str:
    """Return fully qualified table name (platform-agnostic).

    - Databricks: {PROJECT_SLUG}_demo.{schema}.{table}
    - Snowflake:  {PROJECT_SLUG}_demo.{schema}.{table}
    - BigQuery:   {PROJECT_SLUG}_demo.{schema}.{table}  (dataset.table)

    All platforms use a 3-level namespace, so the format is consistent.
    """
    return f"{PROJECT_SLUG}_demo.{schema}.{table}"


def catalog_name() -> str:
    """Return the catalog / database / project-dataset name."""
    return f"{PROJECT_SLUG}_demo"


def volume_path() -> str:
    """Return the landing zone path (Databricks-specific, override for others)."""
    if PLATFORM_TYPE == "databricks":
        return f"/Volumes/{catalog_name()}/{SCHEMA_BRONZE}/{LANDING_ZONE}"
    elif PLATFORM_TYPE == "snowflake":
        return f"@{catalog_name()}.{SCHEMA_BRONZE}.{LANDING_ZONE}"
    elif PLATFORM_TYPE == "bigquery":
        return f"gs://{PROJECT_SLUG}-data-landing/"
    else:
        return f"./output/{PROJECT_SLUG}/raw/"


def print_status(step: str, message: str, success: bool = True) -> None:
    """Print a formatted status message."""
    icon = "[OK]" if success else "[NG]"
    print(f"{icon} [{step}] {message}")


# ------------------------------------------------------------------------------
# Table Definitions (common across all platforms)
# ------------------------------------------------------------------------------

# Bronze layer tables (raw ingestion, prefixed with raw_)
BRONZE_TABLES = [
    "raw_customers",
    "raw_accounts",
    "raw_transactions",
    "raw_campaigns",
    "raw_campaign_responses",
    "raw_web_events",
]

# Silver layer tables (cleansed)
SILVER_TABLES = [
    "customers",
    "accounts",
    "transactions",
    "campaigns",
    "campaign_responses",
    "web_events",
]

# Gold layer tables (aggregated / business logic)
GOLD_TABLES = [
    "customer_360",
    "campaign_effectiveness",
    "daily_summary",
    "segment_analysis",
]
