# ARCADIA Data Platform - Snowflake Implementation (Stub)

> **Status**: Stub - Snowflake 固有スクリプトは今後の ARCADIA 拡張で対応予定。
> 現在は Databricks 実装を参照し、以下のマッピングテーブルに基づいて手動で置き換えてください。

## Databricks -> Snowflake マッピング

| カテゴリ | Databricks | Snowflake | 備考 |
|---------|-----------|-----------|------|
| **カタログ** | Unity Catalog | Snowflake Database | `CREATE DATABASE` |
| **スキーマ** | Unity Catalog Schema | Snowflake Schema | `CREATE SCHEMA` |
| **Landing Zone** | Unity Catalog Volume | Internal/External Stage | `CREATE STAGE` |
| **テーブル形式** | Delta Lake | Iceberg / Native | Snowflake managed |
| **Raw取込** | COPY INTO (CSV/JSON) | COPY INTO / Snowpipe | ほぼ同一構文 |
| **増分取込** | Auto Loader (cloudFiles) | Snowpipe (auto-ingest) | S3 Event → SQS → Snowpipe |
| **増分更新** | MERGE INTO (Delta) | MERGE INTO | ほぼ同一構文 |
| **ストリーム処理** | Structured Streaming | Streams + Tasks | Change tracking |
| **データ品質** | DLT Expectations | Pre/Post-actions + Alerts | Custom SQL |
| **クラスタリング** | Liquid Clustering | Automatic Clustering | Snowflake auto |
| **SQL実行** | Serverless SQL Warehouse | Virtual Warehouse | `CREATE WAREHOUSE` |
| **自然言語分析** | Genie Space | Cortex Analyst | Semantic model YAML |
| **ダッシュボード** | AI/BI Dashboard | Streamlit in Snowflake | Python-based |
| **ML** | Mosaic AI / MLflow | Snowpark ML / Cortex | Python UDFs |
| **ガバナンス** | Unity Catalog ACL | RBAC / DAC | `GRANT` statements |

## 環境変数

| 変数名 | 説明 | 例 |
|--------|------|-----|
| `SNOWFLAKE_ACCOUNT` | アカウント識別子 | `xy12345.ap-northeast-1` |
| `SNOWFLAKE_USER` | ユーザー名 | `DEMO_USER` |
| `SNOWFLAKE_PASSWORD` | パスワード | `***` |
| `SNOWFLAKE_WAREHOUSE` | Warehouse名 | `DEMO_WH` |
| `SNOWFLAKE_DATABASE` | Database名 | `{{PROJECT_SLUG}}_DEMO` |
| `SNOWFLAKE_ROLE` | ロール名 | `SYSADMIN` |

## スクリプト置換ガイド

### 01_setup_infrastructure

```sql
-- Databricks:
-- CREATE CATALOG IF NOT EXISTS {CATALOG} MANAGED LOCATION '...'
-- CREATE SCHEMA IF NOT EXISTS {CATALOG}.{schema}
-- CREATE VOLUME IF NOT EXISTS ...

-- Snowflake equivalent:
CREATE DATABASE IF NOT EXISTS {{PROJECT_SLUG}}_DEMO;
CREATE SCHEMA IF NOT EXISTS {{PROJECT_SLUG}}_DEMO.BRONZE;
CREATE SCHEMA IF NOT EXISTS {{PROJECT_SLUG}}_DEMO.SILVER;
CREATE SCHEMA IF NOT EXISTS {{PROJECT_SLUG}}_DEMO.GOLD;
CREATE STAGE IF NOT EXISTS {{PROJECT_SLUG}}_DEMO.BRONZE.RAW_LANDING;
```

### 03_bronze_ingestion

```sql
-- Databricks COPY INTO -> Snowflake COPY INTO (nearly identical syntax)
COPY INTO {{PROJECT_SLUG}}_DEMO.BRONZE.RAW_CUSTOMERS
FROM @{{PROJECT_SLUG}}_DEMO.BRONZE.RAW_LANDING/customers/
FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '"')
ON_ERROR = 'CONTINUE';
```

### 04_silver_transform

```sql
-- MERGE INTO syntax is nearly identical between Databricks and Snowflake
MERGE INTO {{PROJECT_SLUG}}_DEMO.SILVER.CUSTOMERS AS tgt
USING (
    SELECT DISTINCT * FROM {{PROJECT_SLUG}}_DEMO.BRONZE.RAW_CUSTOMERS
    WHERE customer_id IS NOT NULL
) AS src
ON tgt.customer_id = src.customer_id
WHEN MATCHED THEN UPDATE SET ...
WHEN NOT MATCHED THEN INSERT ...;
```

### 05_gold_aggregate / 06_setup_analytics

```sql
-- CREATE OR REPLACE TABLE ... AS SELECT ...
-- SQL syntax is largely compatible; adjust function names as needed:
--   MODE() -> Snowflake: MODE() (supported)
--   COLLECT_SET() -> ARRAY_AGG(DISTINCT ...)
--   PERCENTILE_APPROX() -> APPROX_PERCENTILE()
```

## Snowpipe 自動取込設定（本番推奨）

```sql
-- 1. S3 Event Notification -> SQS -> Snowpipe
CREATE PIPE {{PROJECT_SLUG}}_DEMO.BRONZE.CUSTOMERS_PIPE
    AUTO_INGEST = TRUE
    AS
    COPY INTO {{PROJECT_SLUG}}_DEMO.BRONZE.RAW_CUSTOMERS
    FROM @{{PROJECT_SLUG}}_DEMO.BRONZE.RAW_LANDING/customers/
    FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER = 1);
```

## 今後の対応予定

- [ ] Snowflake 固有の `.py.tmpl` スクリプト群の作成
- [ ] Snowpark Python による ETL パイプライン実装
- [ ] Cortex Analyst セマンティックモデル (YAML) テンプレート
- [ ] Streamlit in Snowflake ダッシュボードテンプレート
- [ ] Snowflake Notebooks 形式への変換ツール

---

*Generated by ARCADIA Framework - Phase F: Data Platform Templates (Snowflake Stub)*
